{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "933c05f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RH</th>\n",
       "      <th>UPV</th>\n",
       "      <th>SandT</th>\n",
       "      <th>CementT</th>\n",
       "      <th>CompStr</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.00000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.416000</td>\n",
       "      <td>4.04768</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>31.838800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.287328</td>\n",
       "      <td>0.07825</td>\n",
       "      <td>0.749833</td>\n",
       "      <td>0.490881</td>\n",
       "      <td>2.744321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.90000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>4.05000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>32.350000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.11000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.300000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.26000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.700000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               RH        UPV       SandT     CementT     CompStr  Unnamed: 5  \\\n",
       "count  250.000000  250.00000  250.000000  250.000000  250.000000         0.0   \n",
       "mean    29.416000    4.04768    1.800000    1.600000   31.838800         NaN   \n",
       "std      2.287328    0.07825    0.749833    0.490881    2.744321         NaN   \n",
       "min     24.000000    3.90000    1.000000    1.000000   26.600000         NaN   \n",
       "25%     28.000000    4.00000    1.000000    1.000000   29.200000         NaN   \n",
       "50%     30.000000    4.05000    2.000000    2.000000   32.350000         NaN   \n",
       "75%     32.000000    4.11000    2.000000    2.000000   34.300000         NaN   \n",
       "max     34.000000    4.26000    3.000000    2.000000   36.700000         NaN   \n",
       "\n",
       "       Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  Unnamed: 10  \n",
       "count         0.0         0.0         0.0         0.0          0.0  \n",
       "mean          NaN         NaN         NaN         NaN          NaN  \n",
       "std           NaN         NaN         NaN         NaN          NaN  \n",
       "min           NaN         NaN         NaN         NaN          NaN  \n",
       "25%           NaN         NaN         NaN         NaN          NaN  \n",
       "50%           NaN         NaN         NaN         NaN          NaN  \n",
       "75%           NaN         NaN         NaN         NaN          NaN  \n",
       "max           NaN         NaN         NaN         NaN          NaN  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('Model Fitting.csv')\n",
    "# number of rows and columns\n",
    "dataframe.shape\n",
    "dataframe.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c6c6ffca",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataframe\u001b[39m.\u001b[39;49mgroupby(\u001b[39m4\u001b[39;49m)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   8399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mYou have to supply one of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mby\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8400\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m-> 8402\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   8403\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8404\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   8405\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   8406\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   8407\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   8408\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8409\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   8410\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,\n\u001b[0;32m   8411\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8412\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8413\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    966\u001b[0m         obj,\n\u001b[0;32m    967\u001b[0m         keys,\n\u001b[0;32m    968\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    969\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    970\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    971\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    972\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    973\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    974\u001b[0m     )\n\u001b[0;32m    976\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    977\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    886\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 888\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    889\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    891\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "dataframe.groupby(4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4edd6692",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[60] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# seperating data and labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m y \u001b[39m=\u001b[39m dataset[\u001b[39m60\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(x)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:5399\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5251\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5252\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5253\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5260\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5261\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5262\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5263\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5264\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5397\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5398\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5400\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5401\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5402\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5403\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5404\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5405\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5406\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5407\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[60] not found in axis'"
     ]
    }
   ],
   "source": [
    "# seperating data and labels\n",
    "x = dataset.drop(columns=60,axis=1)\n",
    "y = dataset[60]\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "99466ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[105], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# training and test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train , x_test , y_train , y_test \u001b[39m=\u001b[39m train_test_split(x,y,test_size\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,stratify\u001b[39m=\u001b[39;49my, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# x_train.head()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(x_train)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2583\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2579\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2581\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2583\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[0;32m   2585\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2586\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2587\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2588\u001b[0m     )\n\u001b[0;32m   2589\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1689\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1659\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m \n\u001b[0;32m   1661\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1686\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1689\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1690\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2078\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2076\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2077\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 2078\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2079\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2080\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2081\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2082\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2083\u001b[0m     )\n\u001b[0;32m   2085\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[0;32m   2086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2087\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2088\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2089\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# training and test data\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.1,stratify=y, random_state=42)\n",
    "# x_train.head()\n",
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "40b838f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model training using the logistic regression\n",
    "model = LogisticRegression()\n",
    "# training the data\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5dfcdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2a1860bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 798.1569 - mse: 798.1569 - mae: 28.1326\n",
      "Epoch 2/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 676.9352 - mse: 676.9352 - mae: 25.9032\n",
      "Epoch 3/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 566.3226 - mse: 566.3226 - mae: 23.6809\n",
      "Epoch 4/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 461.9702 - mse: 461.9702 - mae: 21.3779\n",
      "Epoch 5/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 365.6388 - mse: 365.6388 - mae: 19.0051\n",
      "Epoch 6/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 279.0459 - mse: 279.0459 - mae: 16.5789\n",
      "Epoch 7/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 204.2043 - mse: 204.2043 - mae: 14.1505\n",
      "Epoch 8/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 142.7702 - mse: 142.7702 - mae: 11.8099\n",
      "Epoch 9/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 97.2166 - mse: 97.2166 - mae: 9.6880\n",
      "Epoch 10/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 62.7438 - mse: 62.7438 - mae: 7.7401\n",
      "Epoch 11/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 38.3390 - mse: 38.3390 - mae: 5.9685\n",
      "Epoch 12/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 22.0933 - mse: 22.0933 - mae: 4.4120\n",
      "Epoch 13/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 12.0804 - mse: 12.0804 - mae: 3.1620\n",
      "Epoch 14/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 6.7929 - mse: 6.7929 - mae: 2.2833\n",
      "Epoch 15/150\n",
      "10/10 [==============================] - 0s 776us/step - loss: 4.1688 - mse: 4.1688 - mae: 1.7512\n",
      "Epoch 16/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 3.0582 - mse: 3.0582 - mae: 1.4261\n",
      "Epoch 17/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.6650 - mse: 2.6650 - mae: 1.2704\n",
      "Epoch 18/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5716 - mse: 2.5716 - mae: 1.2047\n",
      "Epoch 19/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5484 - mse: 2.5484 - mae: 1.1835\n",
      "Epoch 20/150\n",
      "10/10 [==============================] - 0s 998us/step - loss: 2.5377 - mse: 2.5377 - mae: 1.1757\n",
      "Epoch 21/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5376 - mse: 2.5376 - mae: 1.1723\n",
      "Epoch 22/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5361 - mse: 2.5361 - mae: 1.1711\n",
      "Epoch 23/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5326 - mse: 2.5326 - mae: 1.1724\n",
      "Epoch 24/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5308 - mse: 2.5308 - mae: 1.1751\n",
      "Epoch 25/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5346 - mse: 2.5346 - mae: 1.1797\n",
      "Epoch 26/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5324 - mse: 2.5324 - mae: 1.1813\n",
      "Epoch 27/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5281 - mse: 2.5281 - mae: 1.1783\n",
      "Epoch 28/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5261 - mse: 2.5261 - mae: 1.1740\n",
      "Epoch 29/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5248 - mse: 2.5248 - mae: 1.1712\n",
      "Epoch 30/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5222 - mse: 2.5222 - mae: 1.1693\n",
      "Epoch 31/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5231 - mse: 2.5231 - mae: 1.1707\n",
      "Epoch 32/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5194 - mse: 2.5194 - mae: 1.1710\n",
      "Epoch 33/150\n",
      "10/10 [==============================] - 0s 995us/step - loss: 2.5207 - mse: 2.5207 - mae: 1.1657\n",
      "Epoch 34/150\n",
      "10/10 [==============================] - 0s 884us/step - loss: 2.5223 - mse: 2.5223 - mae: 1.1633\n",
      "Epoch 35/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5201 - mse: 2.5201 - mae: 1.1636\n",
      "Epoch 36/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5179 - mse: 2.5179 - mae: 1.1678\n",
      "Epoch 37/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5248 - mse: 2.5248 - mae: 1.1743\n",
      "Epoch 38/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5199 - mse: 2.5199 - mae: 1.1731\n",
      "Epoch 39/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.5160 - mse: 2.5160 - mae: 1.1702\n",
      "Epoch 40/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5160 - mse: 2.5160 - mae: 1.1660\n",
      "Epoch 41/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5163 - mse: 2.5163 - mae: 1.1648\n",
      "Epoch 42/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5234 - mse: 2.5234 - mae: 1.1655\n",
      "Epoch 43/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5165 - mse: 2.5165 - mae: 1.1649\n",
      "Epoch 44/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5153 - mse: 2.5153 - mae: 1.1666\n",
      "Epoch 45/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5140 - mse: 2.5140 - mae: 1.1665\n",
      "Epoch 46/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5139 - mse: 2.5139 - mae: 1.1665\n",
      "Epoch 47/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5136 - mse: 2.5136 - mae: 1.1657\n",
      "Epoch 48/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5151 - mse: 2.5151 - mae: 1.1675\n",
      "Epoch 49/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5150 - mse: 2.5150 - mae: 1.1692\n",
      "Epoch 50/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5139 - mse: 2.5139 - mae: 1.1699\n",
      "Epoch 51/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.5129 - mse: 2.5129 - mae: 1.1702\n",
      "Epoch 52/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5109 - mse: 2.5109 - mae: 1.1677\n",
      "Epoch 53/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5120 - mse: 2.5120 - mae: 1.1653\n",
      "Epoch 54/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.5119 - mse: 2.5119 - mae: 1.1639\n",
      "Epoch 55/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5129 - mse: 2.5129 - mae: 1.1641\n",
      "Epoch 56/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5084 - mse: 2.5084 - mae: 1.1645\n",
      "Epoch 57/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5103 - mse: 2.5103 - mae: 1.1688\n",
      "Epoch 58/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5189 - mse: 2.5189 - mae: 1.1668\n",
      "Epoch 59/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5146 - mse: 2.5146 - mae: 1.1694\n",
      "Epoch 60/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.5120 - mse: 2.5120 - mae: 1.1699\n",
      "Epoch 61/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5087 - mse: 2.5087 - mae: 1.1687\n",
      "Epoch 62/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5073 - mse: 2.5073 - mae: 1.1666\n",
      "Epoch 63/150\n",
      "10/10 [==============================] - 0s 993us/step - loss: 2.5080 - mse: 2.5080 - mae: 1.1661\n",
      "Epoch 64/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5046 - mse: 2.5046 - mae: 1.1638\n",
      "Epoch 65/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.5062 - mse: 2.5062 - mae: 1.1611\n",
      "Epoch 66/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5095 - mse: 2.5095 - mae: 1.1641\n",
      "Epoch 67/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5030 - mse: 2.5030 - mae: 1.1615\n",
      "Epoch 68/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5039 - mse: 2.5039 - mae: 1.1603\n",
      "Epoch 69/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5034 - mse: 2.5034 - mae: 1.1611\n",
      "Epoch 70/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5028 - mse: 2.5028 - mae: 1.1629\n",
      "Epoch 71/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.5030 - mse: 2.5030 - mae: 1.1647\n",
      "Epoch 72/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5012 - mse: 2.5012 - mae: 1.1637\n",
      "Epoch 73/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.5028 - mse: 2.5028 - mae: 1.1642\n",
      "Epoch 74/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5000 - mse: 2.5000 - mae: 1.1621\n",
      "Epoch 75/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5037 - mse: 2.5037 - mae: 1.1596\n",
      "Epoch 76/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.5012 - mse: 2.5012 - mae: 1.1578\n",
      "Epoch 77/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4983 - mse: 2.4983 - mae: 1.1598\n",
      "Epoch 78/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5051 - mse: 2.5051 - mae: 1.1644\n",
      "Epoch 79/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4990 - mse: 2.4990 - mae: 1.1619\n",
      "Epoch 80/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5010 - mse: 2.5010 - mae: 1.1620\n",
      "Epoch 81/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4981 - mse: 2.4981 - mae: 1.1595\n",
      "Epoch 82/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5168 - mse: 2.5168 - mae: 1.1604\n",
      "Epoch 83/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5018 - mse: 2.5018 - mae: 1.1594\n",
      "Epoch 84/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.5022 - mse: 2.5022 - mae: 1.1676\n",
      "Epoch 85/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.5000 - mse: 2.5000 - mae: 1.1634\n",
      "Epoch 86/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4960 - mse: 2.4960 - mae: 1.1585\n",
      "Epoch 87/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5052 - mse: 2.5052 - mae: 1.1572\n",
      "Epoch 88/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4938 - mse: 2.4938 - mae: 1.1573\n",
      "Epoch 89/150\n",
      "10/10 [==============================] - 0s 998us/step - loss: 2.4943 - mse: 2.4943 - mae: 1.1616\n",
      "Epoch 90/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4973 - mse: 2.4973 - mae: 1.1666\n",
      "Epoch 91/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4947 - mse: 2.4947 - mae: 1.1615\n",
      "Epoch 92/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4992 - mse: 2.4992 - mae: 1.1561\n",
      "Epoch 93/150\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 2.4944 - mse: 2.4944 - mae: 1.1556\n",
      "Epoch 94/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4928 - mse: 2.4928 - mae: 1.1571\n",
      "Epoch 95/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.4927 - mse: 2.4927 - mae: 1.1607\n",
      "Epoch 96/150\n",
      "10/10 [==============================] - 0s 776us/step - loss: 2.4928 - mse: 2.4928 - mae: 1.1620\n",
      "Epoch 97/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4920 - mse: 2.4920 - mae: 1.1596\n",
      "Epoch 98/150\n",
      "10/10 [==============================] - 0s 998us/step - loss: 2.4949 - mse: 2.4949 - mae: 1.1550\n",
      "Epoch 99/150\n",
      "10/10 [==============================] - 0s 776us/step - loss: 2.4971 - mse: 2.4971 - mae: 1.1598\n",
      "Epoch 100/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4923 - mse: 2.4923 - mae: 1.1596\n",
      "Epoch 101/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4924 - mse: 2.4924 - mae: 1.1594\n",
      "Epoch 102/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4919 - mse: 2.4919 - mae: 1.1577\n",
      "Epoch 103/150\n",
      "10/10 [==============================] - 0s 832us/step - loss: 2.4970 - mse: 2.4970 - mae: 1.1537\n",
      "Epoch 104/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4913 - mse: 2.4913 - mae: 1.1538\n",
      "Epoch 105/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4893 - mse: 2.4893 - mae: 1.1593\n",
      "Epoch 106/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5354 - mse: 2.5354 - mae: 1.1888\n",
      "Epoch 107/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.4944 - mse: 2.4944 - mae: 1.1738\n",
      "Epoch 108/150\n",
      "10/10 [==============================] - 0s 889us/step - loss: 2.5068 - mse: 2.5068 - mae: 1.1607\n",
      "Epoch 109/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4903 - mse: 2.4903 - mae: 1.1535\n",
      "Epoch 110/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4925 - mse: 2.4925 - mae: 1.1585\n",
      "Epoch 111/150\n",
      "10/10 [==============================] - 0s 776us/step - loss: 2.4921 - mse: 2.4921 - mae: 1.1658\n",
      "Epoch 112/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4921 - mse: 2.4921 - mae: 1.1603\n",
      "Epoch 113/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4884 - mse: 2.4884 - mae: 1.1597\n",
      "Epoch 114/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4952 - mse: 2.4952 - mae: 1.1566\n",
      "Epoch 115/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.4855 - mse: 2.4855 - mae: 1.1563\n",
      "Epoch 116/150\n",
      "10/10 [==============================] - 0s 883us/step - loss: 2.4879 - mse: 2.4879 - mae: 1.1604\n",
      "Epoch 117/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4876 - mse: 2.4876 - mae: 1.1583\n",
      "Epoch 118/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4912 - mse: 2.4912 - mae: 1.1577\n",
      "Epoch 119/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4860 - mse: 2.4860 - mae: 1.1582\n",
      "Epoch 120/150\n",
      "10/10 [==============================] - 0s 907us/step - loss: 2.4886 - mse: 2.4886 - mae: 1.1641\n",
      "Epoch 121/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4953 - mse: 2.4953 - mae: 1.1608\n",
      "Epoch 122/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4985 - mse: 2.4985 - mae: 1.1543\n",
      "Epoch 123/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5022 - mse: 2.5022 - mae: 1.1672\n",
      "Epoch 124/150\n",
      "10/10 [==============================] - 0s 922us/step - loss: 2.5060 - mse: 2.5060 - mae: 1.1855\n",
      "Epoch 125/150\n",
      "10/10 [==============================] - 0s 989us/step - loss: 2.4869 - mse: 2.4869 - mae: 1.1675\n",
      "Epoch 126/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4927 - mse: 2.4927 - mae: 1.1547\n",
      "Epoch 127/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4846 - mse: 2.4846 - mae: 1.1508\n",
      "Epoch 128/150\n",
      "10/10 [==============================] - 0s 890us/step - loss: 2.4906 - mse: 2.4906 - mae: 1.1609\n",
      "Epoch 129/150\n",
      "10/10 [==============================] - 0s 886us/step - loss: 2.4933 - mse: 2.4933 - mae: 1.1573\n",
      "Epoch 130/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4932 - mse: 2.4932 - mae: 1.1649\n",
      "Epoch 131/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.5001 - mse: 2.5001 - mae: 1.1639\n",
      "Epoch 132/150\n",
      "10/10 [==============================] - 0s 922us/step - loss: 2.4879 - mse: 2.4879 - mae: 1.1532\n",
      "Epoch 133/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4846 - mse: 2.4846 - mae: 1.1499\n",
      "Epoch 134/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4890 - mse: 2.4890 - mae: 1.1549\n",
      "Epoch 135/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4923 - mse: 2.4923 - mae: 1.1558\n",
      "Epoch 136/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4801 - mse: 2.4801 - mae: 1.1526\n",
      "Epoch 137/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.4925 - mse: 2.4925 - mae: 1.1654\n",
      "Epoch 138/150\n",
      "10/10 [==============================] - 0s 897us/step - loss: 2.4977 - mse: 2.4977 - mae: 1.1578\n",
      "Epoch 139/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4799 - mse: 2.4799 - mae: 1.1511\n",
      "Epoch 140/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4854 - mse: 2.4854 - mae: 1.1604\n",
      "Epoch 141/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4868 - mse: 2.4868 - mae: 1.1584\n",
      "Epoch 142/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4857 - mse: 2.4857 - mae: 1.1589\n",
      "Epoch 143/150\n",
      "10/10 [==============================] - 0s 997us/step - loss: 2.4834 - mse: 2.4834 - mae: 1.1619\n",
      "Epoch 144/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4824 - mse: 2.4824 - mae: 1.1589\n",
      "Epoch 145/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4851 - mse: 2.4851 - mae: 1.1628\n",
      "Epoch 146/150\n",
      "10/10 [==============================] - 0s 833us/step - loss: 2.4916 - mse: 2.4916 - mae: 1.1598\n",
      "Epoch 147/150\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.4784 - mse: 2.4784 - mae: 1.1529\n",
      "Epoch 148/150\n",
      "10/10 [==============================] - 0s 969us/step - loss: 2.4785 - mse: 2.4785 - mae: 1.1551\n",
      "Epoch 149/150\n",
      "10/10 [==============================] - 0s 994us/step - loss: 2.4828 - mse: 2.4828 - mae: 1.1542\n",
      "Epoch 150/150\n",
      "10/10 [==============================] - 0s 887us/step - loss: 2.4794 - mse: 2.4794 - mae: 1.1540\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train,y_train,epochs=150,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd56ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[32.    4.05  1.    1.  ], Predicted=[34.59313]\n"
     ]
    }
   ],
   "source": [
    "xnew = np.array([[32,4.05,1,1]])\n",
    "ynew = model.predict(xnew)\n",
    "print(\"X=%s, Predicted=%s\"%(xnew[0],ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84f8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypre = model.predict(x_test)\n",
    "confusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
